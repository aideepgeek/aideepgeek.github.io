---
layout: post
title:  "AI日报 2025/12/6"
author: DeepGeekAI
categories: [ AI daliy ]
tags: [AI]
image: https://picsum.photos/seed/25/1200/900
description: "NVIDIA发布20年来最大更新的CUDA Toolkit 13.1，核心是推出CUDA Tile编程模型，简化底层硬件抽象并提高代码可移植性。
腾讯发布参数高达406B的混元2.0大模型，采用MoE架构并支持256K超长上下文，综合推理能力稳居国内第一梯队。
图灵奖得主LeCun提出GenMimic新方法，使机器人能通过观看AI生成视频实现零样本动作复现，具备"模仿大师”技能。"
featured: true
hidden: true
---



## AI日报 2025/12/6



### **今日摘要**

```
NVIDIA发布20年来最大更新的CUDA Toolkit 13.1，核心是推出CUDA Tile编程模型，简化底层硬件抽象并提高代码可移植性。
腾讯发布参数高达406B的混元2.0大模型，采用MoE架构并支持256K超长上下文，综合推理能力稳居国内第一梯队。
图灵奖得主LeCun提出GenMimic新方法，使机器人能通过观看AI生成视频实现零样本动作复现，具备"模仿大师”技能。
```



### **今日AI资讯**

#### **新闻快讯**

1.  **NVIDIA CUDA Toolkit 13.1** 正式发布，官方称这是 **20 年来最大的一次更新**。此次更新的核心包括推出基于 tile 的编程模型 **NVIDIA CUDA Tile**，该模型能够抽象化专用硬件（例如**张量核心**）的细节；暴露 Runtime API 中的 **green contexts**；以及一本完全重写的 **CUDA 编程指南**。[[原文链接](https://www.jiqizhixin.com/articles/2025-12-06-5)] ![图片描述](https://image.jiqizhixin.com/uploads/editor/e2d7bb98-254a-445e-bd85-0b0d14a77b26/640.png) ![图片描述](https://image.jiqizhixin.com/uploads/editor/9d1c73bb-d9b9-4f6a-9367-0135ecb65fde/640.png)
2.  图灵奖得主 **Yann LeCun** 在一篇最新论文中提出了名为 **GenMimic** 的新方法，使机器人拥有了**"模仿大师”**的技能。该方法能让机器人通过观看 **AI 生成的视频**（如 Wan2.1 或 Sora）实现**零样本（Zero-shot）**复现动作，即使视频存在噪声或变形，机器人也能提取核心动作逻辑并在物理世界中稳妥执行。[[原文链接](https://www.jiqizhixin.com/articles/2025-12-06-4)] ![图片描述](https://image.jiqizhixin.com/uploads/editor/5dc44e32-03e0-4e04-b7a2-bcd68ff2b215/640.png)
3.  北京大学**彭宇新教授团队**针对可见光-红外终身行人重识别（Re-identification）领域，提出了**跨模态知识解耦与对齐方法 CKDA**，该研究已被 **AAAI 2026** 接收。CKDA 通过通用提示模块与专用提示模块显式地**解耦**不同模态的鉴别性信息，解决了单模态专用知识获取与跨模态公共旧知识保留之间的冲突，并在四个常用基准上取得了当前最优性能。[[原文链接](https://www.jiqizhixin.com/articles/2025-12-06-3)] ![图片描述](https://image.jiqizhixin.com/uploads/editor/ab961551-f4e1-4bbc-9298-e446a0496fc7/640.png) ![图片描述](https://image.jiqizhixin.com/uploads/editor/898b7aeb-fece-488c-8a82-5137178e5da8/640.png)
4.  为解决具身智能和视频理解中的**「语义鸿沟」**问题，北京航空航天大学陆峰教授团队联合东京大学，提出了 **TSS（Task-Step-State）框架**，该工作已被 **AAAI 2026** 接收。TSS 框架的核心洞见在于引入**「状态」（State）**作为视觉锚点，重构了过程性知识的层级结构，并采用渐进式"层级展开”预训练策略，以解决抽象文本指令与具象视频像素之间的对齐难题。[[原文链接](https://www.jiqizhixin.com/articles/2025-12-06)] ![图片描述](https://image.jiqizhixin.com/uploads/editor/c532097c-3cf7-4f7d-9d90-49c269a026ae/640.png)
5.  MIT神经科学家 Ev Fedorenko 通过耗时 15 年、扫描约 **1400 个大脑**，识别出一个专门负责语言的**神经网络**，该网络只专注于将**词语与意义**联系起来，而不涉及思考或情绪，被形象地比喻为**「生物版ChatGPT」**。[[原文链接](http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652651919&idx=2&sn=5ff4fd2fad2ed2387527ab5b4d7cc53a&chksm=f036ab45bfa8c1fa47b543433ad84352ea21046bc74785bfffcab3d315b5aa436b7a5a0d451d&scene=0&xtrack=1#rd)]
6.  基于 **100万亿 Token** 的实证数据揭示了 2025 年 AI 发展趋势：**开源模型逆袭**、**推理优化**模型流量飙升至 **50%以上**，用户留存高度依赖模型能否完美解决特定痛点，且亚洲地区的付费使用量显著增长。[[原文链接](http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652651919&idx=1&sn=1e826ec84d73788ba507ca848d9f7679&chksm=f05e191a775a8641b186d75e3136218a26587ddec844115f4f78e8c8329c31bc5acda7f123bb&scene=0&xtrack=1#rd)] ![图片描述](https://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb23TwoKpNQ99IZRiaO5Nj7SptO4DE74m121mHCFKXpakpUoUAdmia2vEkV4lj1dnaib52e0eecXoc0ibA/640?wxtype=jpeg&wxfrom=0)
7.  **智能体A2A**（Agent to Agent）技术已落地**华为新旗舰**手机，实现了手机自动为智能体**"建群”**以解决复杂任务，例如跨城出行中自动协同订票、攻略和打车智能体，这为**鸿蒙开发者**提供了新的生态机遇。[[原文链接](http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247851653&idx=1&sn=1332dd3dfebbc6446407ff5d64405da4&chksm=e90641a63192a36fabc73f3cc4c2a670e6348205d4f50664f3e7ac46a59864cdc5a3a7a7147f&scene=0&xtrack=1#rd)]
8.  针对 AI 图像编辑方法对大量监督数据依赖的问题，百度研究人员提出了 **Video4Edit**，创新性地选择**直接从视频中取材**进行训练。该方法仅使用 **1%的训练数据**，便达到了接近**SOTA**（State-of-the-Art）的效果。[[原文链接](http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247851653&idx=3&sn=949921f1af6ea789f247870d27c5c2b5&chksm=e947ac9b31dbb44657aa84c5ab839241eb4492969932e56fcdc385de400cda28a52f6a41aeaf&scene=0&xtrack=1#rd)]
9.  **腾讯自研大模型混元2.0（Tencent HY2.0）**正式发布，采用**混合专家（MoE）架构**，总参数量高达 **406B**（激活参数 32B），并支持 **256K 超长上下文窗口**。HY2.0 在预训练数据和强化学习策略上显著改进，在数学、科学、代码和指令遵循等复杂推理场景中，综合表现稳居**国内第一梯队**。[[原文链接](https://www.aibase.com/zh/news/23432)] ![图片描述](https://pic.chinaz.com/2025/1206/2025120609461007890.jpg)
10. 基于**"流程即代码”**理念的 AI 自动化案例展示了一个工具，该工具能够通过简单的提示词，自动化找出所有推广过特定**竞品**的**网红（红人）**，并生成包含**联系方式**、推广效果和素材的报告，服务于 **AI SaaS 产品的联盟营销**。[[原文链接](https://mp.weixin.qq.com/s?__biz=MzI1MTUxNzgxMA==&mid=2247499876&idx=1&sn=c36e7967750e8540babe78c0e9c2d054)]

#### **社交媒体**

1.  有开发者对 **CUDA 13.1** 中里程碑式的技术 **CUDA Tile** 进行了分析，指出这一核心变革是将 CUDA 编程从传统的 **SIMT（单指令多线程）模型**（需精细控制线程）转变到**"管数据块”**（Tile 模型）。CUDA Tile 使开发者可以专注于**算法逻辑**，系统自动抽象化并调用底层硬件（如 **Tensor Cores**），极大地简化了编程并提高了代码的**可移植性**。[[原文链接](https://x.com/shao__meng/status/1997281875455541735)]
2.  **NotebookLM 移动端**迎来了史诗级更新，功能基本拉齐了网页端体验。新功能包括支持**信息图**和由 **Nano Banana Pro** 驱动的 **PPT 生成**能力，支持直接拍摄或从手机上传**图片作为文件来源**，并能实现云端保存音频概览播放进度的流转。[[原文链接](https://x.com/op7418/status/1997265866115952714)] ![图片描述](https://pbs.twimg.com/media/G7e2s7ibUAAZlf2?format=jpg&name=orig)
3.  Google DeepMind 举办 **Gemini 3 Pro 黑客松**，鼓励参赛者在 **Google AI Studio** 上构建解决实际问题的应用。活动即日起至 12 月 12 日，将选出 50 位优胜者，每人奖励价值 **10,000 美元**（约 7.2 万人民币）的 **Gemini API 积分**额度。[[原文链接](https://x.com/dotey/status/1997203973959205317)] ![图片描述](https://pbs.twimg.com/media/G7a7AwJa8AAyEyy?format=jpg&name=orig)
4.  **"AI 教父” Geoffrey Hinton** 公开发表观点称，**Google** 正在**"开始超越” OpenAI**，并预测 **Google 将最终获胜**。[[原文链接](https://www.reddit.com/r/artificial/comments/1pf0p2w/godfather_of_ai_geoffrey_hinton_says_google_is/)]